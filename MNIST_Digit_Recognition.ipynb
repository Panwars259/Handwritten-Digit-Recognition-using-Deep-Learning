{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPbCbUObaEe4VF0cc+z026s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Panwars259/Handwritten-Digit-Recognition-using-Deep-Learning/blob/main/MNIST_Digit_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Title: Handwritten Digit Recognition using Deep Learning (MNIST Dataset)**\n",
        "\n",
        "**Introduction**\n",
        "\n",
        "Handwritten digit recognition is one of the most popular and foundational problems in the field of computer vision and deep learning. It serves as an ideal entry point for understanding image classification using neural networks. In this project, we develop a deep learning model to recognize digits (0-9) from grayscale images using the MNIST dataset.\n",
        "\n",
        "This project demonstrates the application of a fully connected neural network (also called a dense neural network) to classify images and achieve high accuracy using techniques like regularization, dropout, and early stopping."
      ],
      "metadata": {
        "id": "YjuK5GGvAa9U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Details:**\n",
        "\n",
        "**Framework used:** TensorFlow with Keras API\n",
        "\n",
        "**Model Type:** Sequential Neural Network\n",
        "\n",
        "**Architecture:**\n",
        "\n",
        "Flatten layer to convert 2D images to 1D\n",
        "\n",
        "Dense hidden layer with 512 neurons (ReLU activation)\n",
        "\n",
        "Dropout for regularization\n",
        "\n",
        "output layer with 10 neurons (Softmax activation for classification)\n",
        "\n",
        "**Optimizer:** Adam\n",
        "\n",
        "**Loss Function:** Sparse Categorical Crossentropy\n",
        "\n",
        "**Metrics:** Accuracy\n",
        "\n",
        "**Regularization:** L2 and Dropout\n",
        "\n",
        "**Training Strategy:** Early stopping and validation split"
      ],
      "metadata": {
        "id": "SjRHhLWUDp_g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Information (MNIST)**\n",
        "\n",
        "**Feature Description:**\n",
        "\n",
        "Name MNIST (Modified National Instute of Standards and Technology)\n",
        "\n",
        "Type Image Classification Dataset\n",
        "\n",
        "Image Size 28 x 28 pixels (grayscale)\n",
        "\n",
        "Classes 10 digits (0 through 9)\n",
        "\n",
        "Total Samples 70,000 images\n",
        "\n",
        "Training Set 60,000 images\n",
        "\n",
        "Test Set 10,000 images\n",
        "\n",
        "Format NumPy Arrays loaded via Tensorflow\n",
        "\n",
        "Source tf.keras.datasets.mnist\n",
        "\n",
        "Each image represents a handwritten digit centered and size-normalized, making it ideal for machine learning tasks."
      ],
      "metadata": {
        "id": "5AOduGcuE5g0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Main Objective:**\n",
        "\n",
        "**The primary goal of this project is to:**\n",
        "\n",
        "Develop a neural network-based image classifier that accurately identifies handwritten digits (0-9) from the MNIST dataset.\n",
        "\n",
        "**Key learning objectives:**\n",
        "\n",
        "Apply deep learning techniques to a real-world image classification problem.\n",
        "\n",
        "Understand how to use regularization and dropout to prevent overfitting.\n",
        "\n",
        "Learn how to use early stopping for efficient training.\n",
        "\n",
        "Evaluate model performance using accuracy metrics."
      ],
      "metadata": {
        "id": "lOvTb_gnDp06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, regularizers"
      ],
      "metadata": {
        "id": "R4qddQ2zJ1BG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensorflow is imported as tf for building and training the neural network\n",
        "\n",
        "from keras (which is part of tensorflow), we're importing:\n",
        "\n",
        "layers: for defining different layers of the neural network.\n",
        "\n",
        "models: for creating a model using the Sequential API.\n",
        "\n",
        "regularizers: for applying L2 regularization to prevent overfitting."
      ],
      "metadata": {
        "id": "xmubmugTKDI3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load the MNIST dataset**"
      ],
      "metadata": {
        "id": "03b3wXFQKmXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "ZXAqhfqqKvak"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loads the MNIST dataset, which contains 70,000 grayscale images of handwritten digits (0-9) sized 28x28 pixels. {max. pixels 255}\n",
        "\n",
        "Splits the dataset into:\n",
        "\n",
        "x_train, y_train: training images and labels (60,000 samples).\n",
        "\n",
        "x_test, y_test: test images and labels (10,000 samples)."
      ],
      "metadata": {
        "id": "2G6-IzYSLSdu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Normalize the pixel values**"
      ],
      "metadata": {
        "id": "4PYK1aRwL53E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "metadata": {
        "id": "7fjE_s8vL_Yh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pixels values range from 0 to 255. This line normalizes them to the rande [0, 1] for faster and more stable training."
      ],
      "metadata": {
        "id": "dWhOgtM2MR-a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build the neural network model**"
      ],
      "metadata": {
        "id": "4Njw5oIWLSJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build improved model\n",
        "model = models.Sequential([\n",
        "    layers.Flatten(input_shape=(28, 28)),\n",
        "    layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "NWlY-Rs9tgAn"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Starts building a sequential (layer-by-layer) model.\n",
        "\n",
        "Flattens each 28x28 image into a 784-dimensional vector (1D array) to feed into a dense layer.\n",
        "\n",
        "Adds a dense (fully connected) layer with:\n",
        "\n",
        "512 neurons.\n",
        "\n",
        "ReLU activation function.\n",
        "\n",
        "L2 regularization to penalize large weights (lambda=0.001) and help prevent overfitting.\n",
        "\n",
        "Dropout layer randomly turns off 30% of the neurons during training to reduce overfitting.\n",
        "\n",
        "Output layer with 10 neurons (one per digit class).\n",
        "\n",
        "Softmax activation converts outputs into probabilities the sum to 1."
      ],
      "metadata": {
        "id": "c-JM9xbvLReC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Why 512 Neurons?\n",
        "\n",
        "Balance Between Learning capacity and Computation too few neurons (e.g., 64 or 128) may underfit the data - the model won't be complex enough to capture all patterns in the input.\n",
        "\n",
        "Too many neurons (e.g., 1024+) may lead to overfitting - especially on smaller datasets like MNIST - and increase training time.\n",
        "\n",
        "512 is a balanced choice, offering enough capacity to learn complex patterns without being overly large.\n",
        "\n",
        "512 is a commonly used number in practice for image datasets like MNIST, especially in early experiments or baseline models.\n",
        "\n",
        "It has shown good results empirically on many similar classification tasks."
      ],
      "metadata": {
        "id": "yPzBVA3IyBws"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **COMPILE THE MODEL**\n"
      ],
      "metadata": {
        "id": "_BzGhCMczjjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "KtgwFf96zi0F"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "prepare the model for training by specifying:\n",
        "\n",
        "adam: optimizer for adjusting weights (adaptive learning rate).\n",
        "\n",
        "sparse_categorical_crossentropy: Loss function used for multi=class classification with integer labels.\n",
        "\n",
        "accuracy: metric to monitor during training and testing."
      ],
      "metadata": {
        "id": "aOMFVtguyBeR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
      ],
      "metadata": {
        "id": "thaNYXwd1CeF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defines a callback to stop training early if the validation loss doesn't improve for 3 consecutive epochs.\n"
      ],
      "metadata": {
        "id": "GUREH7zrDpns"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRAIN THE MODEL**"
      ],
      "metadata": {
        "id": "frFTtFZnDpWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, epochs=50, validation_split=0.2, callbacks=[early_stop])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyHwMMje1oF3",
        "outputId": "ca012804-5869-4939-8249-6b2ea3db6e0b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.8684 - loss: 0.7130 - val_accuracy: 0.9569 - val_loss: 0.2901\n",
            "Epoch 2/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9490 - loss: 0.3081 - val_accuracy: 0.9592 - val_loss: 0.2711\n",
            "Epoch 3/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.9528 - loss: 0.2865 - val_accuracy: 0.9650 - val_loss: 0.2482\n",
            "Epoch 4/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9559 - loss: 0.2708 - val_accuracy: 0.9662 - val_loss: 0.2467\n",
            "Epoch 5/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9594 - loss: 0.2608 - val_accuracy: 0.9651 - val_loss: 0.2386\n",
            "Epoch 6/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9592 - loss: 0.2572 - val_accuracy: 0.9656 - val_loss: 0.2411\n",
            "Epoch 7/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9603 - loss: 0.2525 - val_accuracy: 0.9643 - val_loss: 0.2375\n",
            "Epoch 8/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9599 - loss: 0.2510 - val_accuracy: 0.9671 - val_loss: 0.2272\n",
            "Epoch 9/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9627 - loss: 0.2395 - val_accuracy: 0.9649 - val_loss: 0.2355\n",
            "Epoch 10/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9626 - loss: 0.2416 - val_accuracy: 0.9716 - val_loss: 0.2201\n",
            "Epoch 11/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9619 - loss: 0.2404 - val_accuracy: 0.9696 - val_loss: 0.2195\n",
            "Epoch 12/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 11ms/step - accuracy: 0.9668 - loss: 0.2290 - val_accuracy: 0.9718 - val_loss: 0.2118\n",
            "Epoch 13/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9650 - loss: 0.2252 - val_accuracy: 0.9716 - val_loss: 0.2154\n",
            "Epoch 14/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9626 - loss: 0.2306 - val_accuracy: 0.9703 - val_loss: 0.2123\n",
            "Epoch 15/50\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9658 - loss: 0.2260 - val_accuracy: 0.9677 - val_loss: 0.2183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ycU8Nlo6DpCZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7UeJdEWAUZe"
      },
      "outputs": [],
      "source": []
    }
  ]
}